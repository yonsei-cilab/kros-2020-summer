{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8_5_keras_trainCifar10_preRes50.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz9e1N2DI7SZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#*****************************************************\n",
        "#               Learning rate scheduler\n",
        "#*****************************************************\n",
        "\n",
        "name_list = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "num_classes = 10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = utils.to_categorical(y_train, num_classes)\n",
        "y_test = utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "(datanum, h, w, channum) = x_train.shape\n",
        "(_, outputdim) = y_train.shape\n",
        "\n",
        "\n",
        "\n",
        "#Visualizing CIFAR 10\n",
        "fig = plt.figure()\n",
        "ims = np.random.randint(datanum, size=15)\n",
        "\n",
        "for i in range(15):\n",
        "    subplot = fig.add_subplot(3,5, i+1)\n",
        "    subplot.set_xticks([])\n",
        "    subplot.set_yticks([])\n",
        "    subplot.set_title(\"%s\" %name_list[np.argmax(y_train[ims[i]])])\n",
        "    subplot.imshow(x_train[ims[i],:,:,:])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ********************************************************\n",
        "#               Training\n",
        "# ********************************************************\n",
        "\n",
        "# Training Parameters\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "# *************************************************************\n",
        "#               Model building\n",
        "# *************************************************************\n",
        "\n",
        "\n",
        "conv_base = ResNet50(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(h, w, 3))\n",
        "#conv_base.trainable = False\n",
        "conv_base.summary()\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(100, activation='relu'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(optimizer=optimizers.Adam(lr=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# learning rate schedule\n",
        "# def step_decay(epoch):\n",
        "#     initial_lrate = 0.0001\n",
        "#     drop = 0.1\n",
        "#     epochs_drop = 30.0\n",
        "#     lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
        "#     return lrate\n",
        "\n",
        "# # learning schedule callback\n",
        "# lrate = LearningRateScheduler(step_decay)\n",
        "# callbacks_list = [lrate]\n",
        "\n",
        "history = model.fit(x=x_train, y=y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test),\n",
        "                    #callbacks=callbacks_list, \n",
        "                    verbose=1, shuffle=True)\n",
        "\n",
        "history_dict = history.history\n",
        "history_dict.keys()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# *************************************************************\n",
        "#               Visualization\n",
        "# *************************************************************\n",
        "\n",
        "# Training loss\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Training accuracy\n",
        "plt.clf()   # 그래프를 초기화합니다\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcEn3rd_PFBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import utils\n",
        "import sklearn.metrics as skl\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    #print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, format(cm[i, j], fmt),horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    name_list = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "    num_classes = 10\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "    print('x_train shape:', x_train.shape)\n",
        "    print(x_train.shape[0], 'train samples')\n",
        "    print(x_test.shape[0], 'test samples')\n",
        "    print(x_train.shape[1], 'train samples')\n",
        "    print(x_test.shape[2], 'test samples')\n",
        "\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "\n",
        "    # Convert class vectors to binary class matrices.\n",
        "    y_train = utils.to_categorical(y_train, num_classes)\n",
        "    y_test = utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    (_, outputdim) = y_test.shape\n",
        "\n",
        "\n",
        "    # Load model and weights\n",
        "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "    model_name = 'keras_cifar10_trained_model.h5'\n",
        "    model_path = os.path.join(save_dir, model_name)\n",
        "    model = models.load_model(model_path)\n",
        "    print('Loaded trained model at %s ' % model_path)\n",
        "\n",
        "\n",
        "    #Score trained model.\n",
        "    scores = model.evaluate(x_test, y_test, verbose=2)\n",
        "    print('Test loss:', scores[0])\n",
        "    print('Test accuracy:', scores[1])\n",
        "\n",
        "    target = y_test\n",
        "    pred = model.predict(x_test)\n",
        "\n",
        "\n",
        "    ylabel = np.argmax(target,axis=1)\n",
        "    yhatlabel = np.argmax(pred,axis=1)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cnf_matrix = skl.confusion_matrix(ylabel, yhatlabel)\n",
        "    np.set_printoptions(precision=2)\n",
        "    is_correct = (ylabel == yhatlabel)\n",
        "    acc = np.sum(is_correct * 1) / len(is_correct)\n",
        "    print('accuracy:%.5f' %acc)\n",
        "\n",
        "\n",
        "    # Plot non-normalized confusion matrix\n",
        "    plt.figure()\n",
        "    plot_confusion_matrix(cnf_matrix, classes=name_list,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "    # Plot normalized confusion matrix\n",
        "    plt.figure()\n",
        "    plot_confusion_matrix(cnf_matrix, classes=name_list, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}