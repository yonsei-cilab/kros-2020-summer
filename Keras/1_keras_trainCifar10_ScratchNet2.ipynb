{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8_1_keras_trainCifar10_ScratchNet2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p4-0ijKFgAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# import math\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import utils\n",
        "\n",
        "\n",
        "#*****************************************************\n",
        "#               Standard\n",
        "#*****************************************************\n",
        "\n",
        "\n",
        "name_list = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "num_classes = 10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = utils.to_categorical(y_train, num_classes)\n",
        "y_test = utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "(datanum, h, w, channum) = x_train.shape\n",
        "(_, outputdim) = y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-gAPX2Wwl-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Visualizing CIFAR 10\n",
        "fig = plt.figure()\n",
        "ims = np.random.randint(datanum, size=15)\n",
        "\n",
        "for i in range(15):\n",
        "    subplot = fig.add_subplot(3,5, i+1)\n",
        "    subplot.set_xticks([])\n",
        "    subplot.set_yticks([])\n",
        "    subplot.set_title(\"%s\" %name_list[np.argmax(y_train[ims[i]])])\n",
        "    subplot.imshow(x_train[ims[i],:,:,:])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ********************************************************\n",
        "#               Training\n",
        "# ********************************************************\n",
        "\n",
        "# Training Parameters\n",
        "epochs = 10\n",
        "batch_size = 32\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "231Cl0n8wPNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# *************************************************************\n",
        "#               Model building\n",
        "# *************************************************************\n",
        "\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), padding='same',  activation='relu', input_shape=(h, w, channum)))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), padding='same',  activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.2))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), padding='same',  activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), padding='same',  activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.2))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), padding='same',  activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), padding='same',  activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.2))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(100, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=optimizers.Adam(lr=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(x=x_train, y=y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test),\n",
        "                    verbose=1, shuffle=True)\n",
        "\n",
        "history_dict = history.history\n",
        "print(history_dict.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyI6lcbLv6Dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# *************************************************************\n",
        "#               Visualization\n",
        "# *************************************************************\n",
        "\n",
        "# Training loss\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Training accuracy\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5gx31IIMHvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.metrics as skl\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    #print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, format(cm[i, j], fmt),horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(x_train.shape[0], 'train samples')\n",
        "    print(x_test.shape[0], 'test samples')\n",
        "\n",
        "    #Score trained model.\n",
        "    scores = model.evaluate(x_test, y_test, verbose=2)\n",
        "    print('Test loss:', scores[0])\n",
        "    print('Test accuracy:', scores[1])\n",
        "\n",
        "    target = y_test\n",
        "    pred = model.predict(x_test)\n",
        "\n",
        "\n",
        "    ylabel = np.argmax(target,axis=1)\n",
        "    yhatlabel = np.argmax(pred,axis=1)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cnf_matrix = skl.confusion_matrix(ylabel, yhatlabel)\n",
        "    np.set_printoptions(precision=2)\n",
        "    is_correct = (ylabel == yhatlabel)\n",
        "    acc = np.sum(is_correct * 1) / len(is_correct)\n",
        "    print('accuracy:%.5f' %acc)\n",
        "\n",
        "\n",
        "    # Plot non-normalized confusion matrix\n",
        "    plt.figure()\n",
        "    plot_confusion_matrix(cnf_matrix, classes=name_list,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "    # Plot normalized confusion matrix\n",
        "    plt.figure()\n",
        "    plot_confusion_matrix(cnf_matrix, classes=name_list, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMpNUwG_ZQbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import utils\n",
        "import sklearn.metrics as skl\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "name_list = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "num_classes = 10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = utils.to_categorical(y_train, num_classes)\n",
        "y_test = utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "(datanum, h, w, channum) = x_train.shape\n",
        "(_, outputdim) = y_test.shape\n",
        "\n",
        "\n",
        "#Visualizing CIFAR 10\n",
        "fig = plt.figure()\n",
        "ims = np.random.randint(datanum)\n",
        "img_tensor = x_train[ims, :, :, :]\n",
        "plt.title(\"%s\" %name_list[np.argmax(y_train[ims])])\n",
        "plt.imshow(img_tensor)\n",
        "plt.show()\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "\n",
        "\n",
        "\n",
        "# Load model and weights\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model = models.load_model(model_path)\n",
        "print('Loaded trained model at %s ' % model_path)\n",
        "\n",
        "\n",
        "\n",
        "# 상위 8개 층의 출력을 추출합니다:\n",
        "layer_outputs = [layer.output for layer in model.layers[:16]]\n",
        "# 입력에 대해 8개 층의 출력을 반환하는 모델을 만듭니다\n",
        "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "\n",
        "\n",
        "# 층의 활성화마다 하나씩 8개의 넘파이 배열로 이루어진 리스트를 반환합니다:\n",
        "activations = activation_model.predict(img_tensor)\n",
        "\n",
        "\n",
        "\n",
        "## 층의 이름을 그래프 제목으로 사용합니다\n",
        "layer_names = []\n",
        "for layer in model.layers[:16]:\n",
        "    layer_names.append(layer.name)\n",
        "\n",
        "images_per_row = 16\n",
        "\n",
        "# 특성 맵을 그립니다\n",
        "for layer_name, layer_activation in zip(layer_names, activations):\n",
        "    # 특성 맵에 있는 특성의 수\n",
        "    n_features = layer_activation.shape[-1]\n",
        "\n",
        "    # 특성 맵의 크기는 (1, size, size, n_features)입니다\n",
        "    size = layer_activation.shape[1]\n",
        "\n",
        "    # 활성화 채널을 위한 그리드 크기를 구합니다\n",
        "    n_cols = n_features // images_per_row\n",
        "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
        "\n",
        "    # 각 활성화를 하나의 큰 그리드에 채웁니다\n",
        "    for col in range(n_cols):\n",
        "        for row in range(images_per_row):\n",
        "            channel_image = layer_activation[0,\n",
        "                                             :, :,\n",
        "                                             col * images_per_row + row]\n",
        "            # 그래프로 나타내기 좋게 특성을 처리합니다\n",
        "            channel_image -= channel_image.mean()\n",
        "            channel_image /= channel_image.std()\n",
        "            channel_image *= 64\n",
        "            channel_image += 128\n",
        "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "            display_grid[col * size : (col + 1) * size,\n",
        "                         row * size : (row + 1) * size] = channel_image\n",
        "\n",
        "    # 그리드를 출력합니다\n",
        "    scale = 1. / size\n",
        "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
        "                        scale * display_grid.shape[0]))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}